// NOTE: The following script syntax is valid for database version 5.0 and above.

:param {
  // Define the file path root and the individual file names required for loading.
  // https://neo4j.com/docs/operations-manual/current/configuration/file-locations/
  file_path_root: 'file:///', // Change this to the folder your script can access the files at.
  file_0: 'Products.csv',
  file_1: 'Suppliers.csv',
  file_2: 'SupplierProduct.csv',
  file_3: 'Stores.csv',
  file_4: 'StockLevels.csv',
  file_5: 'PurchaseOrderItem.csv',
  file_6: 'PurchaseOrder.csv',
  file_7: 'Payment.csv',
  file_8: 'Invoice.csv',
  file_9: 'Deliveryitem.csv',
  file_10: 'Delivery.csv',
  file_11: 'Category.csv'
};

// CONSTRAINT creation
// -------------------
//
// Create node uniqueness constraints, ensuring no duplicates for the given node label and ID property exist in the database. This also ensures no duplicates are introduced in future.
//
CREATE CONSTRAINT `productId_Product_uniq` IF NOT EXISTS
FOR (n: `Product`)
REQUIRE (n.`productId`) IS UNIQUE;
CREATE CONSTRAINT `supplierId_Supplier_uniq` IF NOT EXISTS
FOR (n: `Supplier`)
REQUIRE (n.`supplierId`) IS UNIQUE;
CREATE CONSTRAINT `supplierId_SupplierProduct_uniq` IF NOT EXISTS
FOR (n: `SupplierProduct`)
REQUIRE (n.`supplierId`) IS UNIQUE;
CREATE CONSTRAINT `storeId_Store_uniq` IF NOT EXISTS
FOR (n: `Store`)
REQUIRE (n.`storeId`) IS UNIQUE;
CREATE CONSTRAINT `storeId_StockLevel_uniq` IF NOT EXISTS
FOR (n: `StockLevel`)
REQUIRE (n.`storeId`) IS UNIQUE;
CREATE CONSTRAINT `poId_PurchaseOrderItem_uniq` IF NOT EXISTS
FOR (n: `PurchaseOrderItem`)
REQUIRE (n.`poId`) IS UNIQUE;
CREATE CONSTRAINT `poId_PurchaseOrder_uniq` IF NOT EXISTS
FOR (n: `PurchaseOrder`)
REQUIRE (n.`poId`) IS UNIQUE;
CREATE CONSTRAINT `paymentId_Payment_uniq` IF NOT EXISTS
FOR (n: `Payment`)
REQUIRE (n.`paymentId`) IS UNIQUE;
CREATE CONSTRAINT `invoiceId_Invoice_uniq` IF NOT EXISTS
FOR (n: `Invoice`)
REQUIRE (n.`invoiceId`) IS UNIQUE;
CREATE CONSTRAINT `deliveryId_DeliveryItem_uniq` IF NOT EXISTS
FOR (n: `DeliveryItem`)
REQUIRE (n.`deliveryId`) IS UNIQUE;
CREATE CONSTRAINT `deliveryId_Delivery_uniq` IF NOT EXISTS
FOR (n: `Delivery`)
REQUIRE (n.`deliveryId`) IS UNIQUE;
CREATE CONSTRAINT `categoryId_Category_uniq` IF NOT EXISTS
FOR (n: `Category`)
REQUIRE (n.`categoryId`) IS UNIQUE;

:param {
  idsToSkip: []
};

// NODE load
// ---------
//
// Load nodes in batches, one node label at a time. Nodes will be created using a MERGE statement to ensure a node with the same label and ID property remains unique. Pre-existing nodes found by a MERGE statement will have their other properties set to the latest values encountered in a load file.
//
// NOTE: Any nodes with IDs in the 'idsToSkip' list parameter will not be loaded.
LOAD CSV WITH HEADERS FROM ($file_path_root + $file_0) AS row
WITH row
WHERE NOT row.`ProductID` IN $idsToSkip AND NOT toInteger(trim(row.`ProductID`)) IS NULL
CALL (row) {
  MERGE (n: `Product` { `productId`: toInteger(trim(row.`ProductID`)) })
  SET n.`productId` = toInteger(trim(row.`ProductID`))
  SET n.`sku` = row.`SKU`
  SET n.`name` = row.`Name`
  SET n.`costPrice` = toFloat(trim(row.`CostPrice`))
  SET n.`retailPrice` = toFloat(trim(row.`RetailPrice`))
  SET n.`unit` = row.`Unit`
  SET n.`isPerishable` = toLower(trim(row.`IsPerishable`)) IN ['1','true','yes']
  SET n.`reorderThreshold` = toInteger(trim(row.`ReorderThreshold`))
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_1) AS row
WITH row
WHERE NOT row.`SupplierID` IN $idsToSkip AND NOT toInteger(trim(row.`SupplierID`)) IS NULL
CALL (row) {
  MERGE (n: `Supplier` { `supplierId`: toInteger(trim(row.`SupplierID`)) })
  SET n.`supplierId` = toInteger(trim(row.`SupplierID`))
  SET n.`name` = row.`Name`
  SET n.`abn` = row.`ABN`
  SET n.`contactName` = row.`ContactName`
  SET n.`phone` = toInteger(trim(row.`Phone`))
  SET n.`email` = row.`Email`
  SET n.`contractTerms` = row.`ContractTerms`
  SET n.`active` = toLower(trim(row.`Active`)) IN ['1','true','yes']
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_2) AS row
WITH row
WHERE NOT row.`SupplierID` IN $idsToSkip AND NOT toInteger(trim(row.`SupplierID`)) IS NULL
CALL (row) {
  MERGE (n: `SupplierProduct` { `supplierId`: toInteger(trim(row.`SupplierID`)) })
  SET n.`supplierId` = toInteger(trim(row.`SupplierID`))
  SET n.`supplierSku` = row.`SupplierSKU`
  SET n.`leadTimeDays` = toInteger(trim(row.`LeadTimeDays`))
  SET n.`unitCost` = toFloat(trim(row.`UnitCost`))
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_3) AS row
WITH row
WHERE NOT row.`StoreID` IN $idsToSkip AND NOT toInteger(trim(row.`StoreID`)) IS NULL
CALL (row) {
  MERGE (n: `Store` { `storeId`: toInteger(trim(row.`StoreID`)) })
  SET n.`storeId` = toInteger(trim(row.`StoreID`))
  SET n.`name` = row.`Name`
  SET n.`location` = row.`Location`
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_4) AS row
WITH row
WHERE NOT row.`StoreID` IN $idsToSkip AND NOT toInteger(trim(row.`StoreID`)) IS NULL
CALL (row) {
  MERGE (n: `StockLevel` { `storeId`: toInteger(trim(row.`StoreID`)) })
  SET n.`storeId` = toInteger(trim(row.`StoreID`))
  SET n.`quantity` = toInteger(trim(row.`Quantity`))
  SET n.`reorderThreshold` = toInteger(trim(row.`ReorderThreshold`))
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_5) AS row
WITH row
WHERE NOT row.`POID` IN $idsToSkip AND NOT toInteger(trim(row.`POID`)) IS NULL
CALL (row) {
  MERGE (n: `PurchaseOrderItem` { `poId`: toInteger(trim(row.`POID`)) })
  SET n.`poId` = toInteger(trim(row.`POID`))
  SET n.`orderedQuantity` = toInteger(trim(row.`OrderedQty`))
  SET n.`unitCost` = toFloat(trim(row.`UnitCost`))
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_6) AS row
WITH row
WHERE NOT row.`POID` IN $idsToSkip AND NOT toInteger(trim(row.`POID`)) IS NULL
CALL (row) {
  MERGE (n: `PurchaseOrder` { `poId`: toInteger(trim(row.`POID`)) })
  SET n.`poId` = toInteger(trim(row.`POID`))
  // Your script contains the datetime datatype. Our app attempts to convert dates to ISO 8601 date format before passing them to the Cypher function.
  // This conversion cannot be done in a Cypher script load. Please ensure that your CSV file columns are in ISO 8601 date format to ensure equivalent loads.
  SET n.`orderDate` = datetime(row.`OrderDate`)
  // Your script contains the datetime datatype. Our app attempts to convert dates to ISO 8601 date format before passing them to the Cypher function.
  // This conversion cannot be done in a Cypher script load. Please ensure that your CSV file columns are in ISO 8601 date format to ensure equivalent loads.
  SET n.`expectedDate` = datetime(row.`ExpectedDate`)
  SET n.`status` = row.`Status`
  SET n.`totalAmount` = toInteger(trim(row.`TotalAmount`))
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_7) AS row
WITH row
WHERE NOT row.`PaymentID` IN $idsToSkip 
CALL (row) {
  MERGE (n: `Payment` { `paymentId`: toLower(trim(row.`PaymentID`)) IN ['1','true','yes'] })
  SET n.`paymentId` = toLower(trim(row.`PaymentID`)) IN ['1','true','yes']
  // Your script contains the datetime datatype. Our app attempts to convert dates to ISO 8601 date format before passing them to the Cypher function.
  // This conversion cannot be done in a Cypher script load. Please ensure that your CSV file columns are in ISO 8601 date format to ensure equivalent loads.
  SET n.`paymentDate` = datetime(row.`PaymentDate`)
  SET n.`method` = row.`Method`
  SET n.`amount` = toInteger(trim(row.`Amount`))
  SET n.`confirmationNumber` = row.`ConfirmationNumber`
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_8) AS row
WITH row
WHERE NOT row.`InvoiceID` IN $idsToSkip AND NOT toInteger(trim(row.`InvoiceID`)) IS NULL
CALL (row) {
  MERGE (n: `Invoice` { `invoiceId`: toInteger(trim(row.`InvoiceID`)) })
  SET n.`invoiceId` = toInteger(trim(row.`InvoiceID`))
  SET n.`invoiceNumber` = row.`InvoiceNumber`
  // Your script contains the datetime datatype. Our app attempts to convert dates to ISO 8601 date format before passing them to the Cypher function.
  // This conversion cannot be done in a Cypher script load. Please ensure that your CSV file columns are in ISO 8601 date format to ensure equivalent loads.
  SET n.`invoiceDate` = datetime(row.`InvoiceDate`)
  // Your script contains the datetime datatype. Our app attempts to convert dates to ISO 8601 date format before passing them to the Cypher function.
  // This conversion cannot be done in a Cypher script load. Please ensure that your CSV file columns are in ISO 8601 date format to ensure equivalent loads.
  SET n.`dueDate` = datetime(row.`DueDate`)
  SET n.`amount` = toInteger(trim(row.`Amount`))
  SET n.`status` = row.`Status`
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_9) AS row
WITH row
WHERE NOT row.`DeliveryID` IN $idsToSkip AND NOT toInteger(trim(row.`DeliveryID`)) IS NULL
CALL (row) {
  MERGE (n: `DeliveryItem` { `deliveryId`: toInteger(trim(row.`DeliveryID`)) })
  SET n.`deliveryId` = toInteger(trim(row.`DeliveryID`))
  SET n.`deliveredQuantity` = toInteger(trim(row.`DeliveredQty`))
  SET n.`damagedQuantity` = toInteger(trim(row.`DamagedQty`))
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_10) AS row
WITH row
WHERE NOT row.`DeliveryID` IN $idsToSkip AND NOT toInteger(trim(row.`DeliveryID`)) IS NULL
CALL (row) {
  MERGE (n: `Delivery` { `deliveryId`: toInteger(trim(row.`DeliveryID`)) })
  SET n.`deliveryId` = toInteger(trim(row.`DeliveryID`))
  // Your script contains the datetime datatype. Our app attempts to convert dates to ISO 8601 date format before passing them to the Cypher function.
  // This conversion cannot be done in a Cypher script load. Please ensure that your CSV file columns are in ISO 8601 date format to ensure equivalent loads.
  SET n.`deliveryDate` = datetime(row.`DeliveryDate`)
  SET n.`status` = row.`Status`
  SET n.`notes` = row.`Notes`
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_11) AS row
WITH row
WHERE NOT row.`CategoryID` IN $idsToSkip AND NOT toInteger(trim(row.`CategoryID`)) IS NULL
CALL (row) {
  MERGE (n: `Category` { `categoryId`: toInteger(trim(row.`CategoryID`)) })
  SET n.`categoryId` = toInteger(trim(row.`CategoryID`))
  SET n.`name` = row.`Name`
} IN TRANSACTIONS OF 10000 ROWS;


// RELATIONSHIP load
// -----------------
//
// Load relationships in batches, one relationship type at a time. Relationships are created using a MERGE statement, meaning only one relationship of a given type will ever be created between a pair of nodes.
LOAD CSV WITH HEADERS FROM ($file_path_root + $file_0) AS row
WITH row 
CALL (row) {
  MATCH (source: `Product` { `productId`: toInteger(trim(row.`ProductID`)) })
  MATCH (target: `Category` { `categoryId`: toInteger(trim(row.`CategoryID`)) })
  MERGE (source)-[r: `HAS_CATEGORY`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_0) AS row
WITH row 
CALL (row) {
  MATCH (source: `Product` { `productId`: toInteger(trim(row.`ProductID`)) })
  MATCH (target: `Supplier` { `supplierId`: toInteger(trim(row.`DefaultSupplierID`)) })
  MERGE (source)-[r: `SUPPLIED_BY`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_2) AS row
WITH row 
CALL (row) {
  MATCH (source: `SupplierProduct` { `supplierId`: toInteger(trim(row.`SupplierID`)) })
  MATCH (target: `Supplier` { `supplierId`: toInteger(trim(row.`SupplierID`)) })
  MERGE (source)-[r: `HAS_SUPPLIER`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_2) AS row
WITH row 
CALL (row) {
  MATCH (source: `SupplierProduct` { `supplierId`: toInteger(trim(row.`SupplierID`)) })
  MATCH (target: `Product` { `productId`: toInteger(trim(row.`ProductID`)) })
  MERGE (source)-[r: `FOR_PRODUCT`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_4) AS row
WITH row 
CALL (row) {
  MATCH (source: `StockLevel` { `storeId`: toInteger(trim(row.`StoreID`)) })
  MATCH (target: `Store` { `storeId`: toInteger(trim(row.`StoreID`)) })
  MERGE (source)-[r: `IN_STORE`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_4) AS row
WITH row 
CALL (row) {
  MATCH (source: `StockLevel` { `storeId`: toInteger(trim(row.`StoreID`)) })
  MATCH (target: `Product` { `productId`: toInteger(trim(row.`ProductID`)) })
  MERGE (source)-[r: `OF_PRODUCT`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_5) AS row
WITH row 
CALL (row) {
  MATCH (source: `PurchaseOrderItem` { `poId`: toInteger(trim(row.`POID`)) })
  MATCH (target: `PurchaseOrder` { `poId`: toInteger(trim(row.`POID`)) })
  MERGE (source)-[r: `BELONGS_TO_PURCHASE_ORDER`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_5) AS row
WITH row 
CALL (row) {
  MATCH (source: `PurchaseOrderItem` { `poId`: toInteger(trim(row.`POID`)) })
  MATCH (target: `Product` { `productId`: toInteger(trim(row.`ProductID`)) })
  MERGE (source)-[r: `CONTAINS_PRODUCT`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_6) AS row
WITH row 
CALL (row) {
  MATCH (source: `PurchaseOrder` { `poId`: toInteger(trim(row.`POID`)) })
  MATCH (target: `Supplier` { `supplierId`: toInteger(trim(row.`SupplierID`)) })
  MERGE (source)-[r: `PLACED_WITH_SUPPLIER`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_6) AS row
WITH row 
CALL (row) {
  MATCH (source: `PurchaseOrder` { `poId`: toInteger(trim(row.`POID`)) })
  MATCH (target: `Store` { `storeId`: toInteger(trim(row.`StoreID`)) })
  MERGE (source)-[r: `FOR_STORE`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_7) AS row
WITH row 
CALL (row) {
  MATCH (source: `Payment` { `paymentId`: toLower(trim(row.`PaymentID`)) IN ['1','true','yes'] })
  MATCH (target: `Invoice` { `invoiceId`: toInteger(trim(row.`InvoiceID`)) })
  MERGE (source)-[r: `FOR_INVOICE`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_8) AS row
WITH row 
CALL (row) {
  MATCH (source: `Invoice` { `invoiceId`: toInteger(trim(row.`InvoiceID`)) })
  MATCH (target: `Supplier` { `supplierId`: toInteger(trim(row.`SupplierID`)) })
  MERGE (source)-[r: `FROM_SUPPLIER`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_8) AS row
WITH row 
CALL (row) {
  MATCH (source: `Invoice` { `invoiceId`: toInteger(trim(row.`InvoiceID`)) })
  MATCH (target: `PurchaseOrder` { `poId`: toInteger(trim(row.`POID`)) })
  MERGE (source)-[r: `FOR_PURCHASE_ORDER`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_9) AS row
WITH row 
CALL (row) {
  MATCH (source: `DeliveryItem` { `deliveryId`: toInteger(trim(row.`DeliveryID`)) })
  MATCH (target: `Delivery` { `deliveryId`: toInteger(trim(row.`DeliveryID`)) })
  MERGE (source)-[r: `BELONGS_TO_DELIVERY`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_9) AS row
WITH row 
CALL (row) {
  MATCH (source: `DeliveryItem` { `deliveryId`: toInteger(trim(row.`DeliveryID`)) })
  MATCH (target: `Product` { `productId`: toInteger(trim(row.`ProductID`)) })
  MERGE (source)-[r: `CONTAINS_PRODUCT`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_10) AS row
WITH row 
CALL (row) {
  MATCH (source: `Delivery` { `deliveryId`: toInteger(trim(row.`DeliveryID`)) })
  MATCH (target: `PurchaseOrder` { `poId`: toInteger(trim(row.`POID`)) })
  MERGE (source)-[r: `FULFILLS_PURCHASE_ORDER`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;

LOAD CSV WITH HEADERS FROM ($file_path_root + $file_11) AS row
WITH row 
CALL (row) {
  MATCH (source: `Category` { `categoryId`: toInteger(trim(row.`CategoryID`)) })
  MATCH (target: `Category` { `categoryId`: toInteger(trim(row.`ParentCategoryID`)) })
  MERGE (source)-[r: `HAS_PARENT_CATEGORY`]->(target)
} IN TRANSACTIONS OF 10000 ROWS;
